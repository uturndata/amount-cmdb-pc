import boto3
import hvac
import json
import kafka
from aiohttp import web
from os import env


def handle_notification(notification: str) -> bool:
    """
    Returns true/false if message was handled properly

    Parameters:
        notification(str) (sns topic notification)

    Returns:
        true or false

    """

    return bool

def lookup_resource(resource_id: str, resource_type: str=None) -> dict:
    """
    Makes a request to get resource config history that was changed and the changeset in AWS config

    Parameters:
        resource_id(str): the resource id, such as for 'ec2' i-9f9f9f9f9f9f9f9f
        resource_type(str): [OPTIONAL, default None] - AWS resource type such as AWS::ec2::Host

    Returns:
        dict representation of the json returned by the lookup or None if failed
    """
    try:
        dict = boto3.Config.GetResourceConfigHistory(resource_id, guess_resource_type(resource_id, resource_type))
    except:
        dict = None

    return dict


def guess_resource_type():
    """
    Attempts to find the resource that was changed and the changeset in AWS config

    Parameters:
        resource_id(str): the resource id, such as for 'ec2' i-9f9f9f9f9f9f9f9f
        resource_type(str): [OPTIONAL, default None] - AWS resource type such as AWS::ec2::Host

    Returns:
        resource_type(str)
    """

    #stub
    resource_type = None
    resource_type = aws.resource_type(resource_id)

    return resource_type


async def accept_request(request):
    """
    Returns true/false if request was handled properly

    This will verify valid json packet, validate key fields

    Parameters:
        request (aiohttp.request)

    Returns:
        aiohttp.response
    """

    try:
        json_dict = request.json()
    except:
        aiohttp.response(json={'error': 'could not load json})

    publish_resource_json(json_dict)


def publish_resource_json(json_dict: dict) -> bool:
    """
    Publishes the dict to an kafka queue

    Parameters:
        json_dict (dict) validated dictionary of json data

    Returns:
        status (bool) returns success status
    """

    status = True
    try:
        kafa_queue.publish(json.dumps(json_dict))
    except:
        status = False

    return status


def load_config() -> dict:
    """
    load the config for the endpoints from the designated store

    Parameters:
        none

    Returns:
        dict
    """

    # Load variables from Vault
    if env.get("LOAD_FROM") == "vault":
        dict = load_from_vault()

    # Load variables from Vault
    if env.get("LOAD_FROM") == "aws":
        dict = load_from_aws()

    # Load variables from Vault
    if env.get("LOAD_FROM") == "env":
        dict = load_from_env()

    return dict


def get_kafka_queue(queue_name: str) -> object:
    """
    Get the kafka queue

    Parameters:
        queue_name (str) the name of the kafka queue

    Returns:
        Kafka queue object
    """

    return kafka.client.queue(config['kafka_queue_name])


def get_sqs_queue(queue_name: str) -> object:
    """
    Get the sqs queue

    Parameters:
        queue_name (str) the name of the kafka queue

    Returns:
        ssq queue object
    """

    return boto3.client.sqs(config['kafka_queue_name])


def get_sqs_messages():
    """
    Get the sqs queue

    Parameters:
       None

    Returns:
        ssq queue message
    """

    return sqs_queue.get_message()



def run_sqs_consumer():
    """
    Run the sqs queue

    Parameters:
        None

    Returns:
        Nothing
    """

    try:
        while qm = get_sqs_message():
            resource_id = qm['resource_id']
            resource = lookup_resource(resource_id,guess_resource_type(resource_id))
            publish_resource_json(resource)
            qm.delete()
    except:
        pass # nominally we probably want to fire off an alert here



if __name__ == "__main__":
    try:
        config = load_config()
        kafka_queue = get_kafka_queue(config['kafka_queue'])
        sqs_queue = get_sqs_queue(config['sqs_queue'])
    except:
        exit(1) #fail out - no point here without the queue available

    run_sqs_consumer()